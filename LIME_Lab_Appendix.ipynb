{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThiagoMueller/csci2470labs/blob/main/LIME_Lab_Appendix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dabfeac5-744e-4724-a1a5-a24f9c3943c8",
      "metadata": {
        "id": "dabfeac5-744e-4724-a1a5-a24f9c3943c8"
      },
      "source": [
        "# Lab 4: LIME Appendix\n",
        "\n",
        "This is a quick demonstration on how to save the Keras model in a JSON file and how to save and load trained weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22ffe447-b3ec-4ed9-9f8a-d76fa649bb54",
      "metadata": {
        "id": "22ffe447-b3ec-4ed9-9f8a-d76fa649bb54",
        "outputId": "7822ac03-d32b-408a-a9a9-d701aed28916",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "isColab = \"google.colab\" in sys.modules\n",
        "# this also works:\n",
        "# isColab = \"COLAB_GPU\" in os.environ\n",
        "\n",
        "if isColab:\n",
        "    # os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "    colab_path = (\"/content/drive/Shared drives\"\n",
        "        + \"/CS1470 TAs Fall 2022/Labs/lab04_lime/released_lab\")\n",
        "    sys.path.append(colab_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed6babb2-afd2-49ec-96ff-7357358c7f4b",
      "metadata": {
        "id": "ed6babb2-afd2-49ec-96ff-7357358c7f4b",
        "outputId": "0e40af0f-fdc0-477a-fd42-eaac65fef8ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'preprocess'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c9c8cdaff9ef>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'preprocess'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "# # Killing optional CPU driver warnings\n",
        "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from preprocess import *\n",
        "\n",
        "import json\n",
        "\n",
        "# ensures that we run only on cpu\n",
        "# this environment variable is not permanent\n",
        "# it is valid only for this session\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd1e012b-2f41-4287-9406-7f61b4e54944",
      "metadata": {
        "id": "fd1e012b-2f41-4287-9406-7f61b4e54944"
      },
      "outputs": [],
      "source": [
        "data_path = \"data\"\n",
        "model_path = \"model\"\n",
        "\n",
        "# If you are working on Colab, you need to modify the path your other files too.\n",
        "if isColab:\n",
        "    data_path = f\"{colab_path}/{data_path}\"\n",
        "    model_path = f\"{colab_path}/{model_path}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21c3799a-cf87-4356-af0a-3e6744d43c9c",
      "metadata": {
        "id": "21c3799a-cf87-4356-af0a-3e6744d43c9c"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91e92864-bc0d-4523-82c2-419df9f593f4",
      "metadata": {
        "id": "91e92864-bc0d-4523-82c2-419df9f593f4"
      },
      "outputs": [],
      "source": [
        "# cifar_class_list = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        "#                     \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "# Read entire CIFAR data\n",
        "image_train_full, label_train_full = unpickle_CIFAR(f\"{data_path}/train\")\n",
        "image_test_full, label_test_full = unpickle_CIFAR(f\"{data_path}/test\")\n",
        "\n",
        "# Keep cats and dogs only and throw away the other classes\n",
        "cifar_class_list = [\"cat\", \"dog\"]\n",
        "image_train_uint, label_train = get_subset(image_train_full, label_train_full,\n",
        "                                           class_list=cifar_class_list,\n",
        "                                           num=None)\n",
        "image_test_uint, label_test = get_subset(image_test_full, label_test_full,\n",
        "                                         class_list=cifar_class_list,\n",
        "                                         num=None)\n",
        "\n",
        "# Shuffle\n",
        "seed = 42\n",
        "image_train_uint, label_train = shuffle_data(image_train_uint, label_train, seed)\n",
        "image_test_uint,  label_test  = shuffle_data(image_test_uint,  label_test,  seed)\n",
        "\n",
        "# Normalize the inputs and one-hot encode the outputs\n",
        "image_train = np.float32(image_train_uint/255.0)\n",
        "image_test  = np.float32(image_test_uint/255.0)\n",
        "oh_label_train = one_hot_encode(label_train, cifar_class_list)\n",
        "oh_label_test  = one_hot_encode(label_test,  cifar_class_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee48063f-d263-4844-a3df-faf113814917",
      "metadata": {
        "id": "ee48063f-d263-4844-a3df-faf113814917"
      },
      "source": [
        "## Model Import"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57ed73b4-1c1a-4b39-8faa-42304f599259",
      "metadata": {
        "id": "57ed73b4-1c1a-4b39-8faa-42304f599259"
      },
      "source": [
        "**This is how you can simply import a Keras model from a JSON file.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03258618-962f-4214-a9a8-ed6724322ecc",
      "metadata": {
        "id": "03258618-962f-4214-a9a8-ed6724322ecc",
        "outputId": "d8acc654-212b-4935-95a2-14af0c584a29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"cnn_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Conv1 (Conv2D)              (None, 16, 16, 16)        1216      \n",
            "                                                                 \n",
            " Conv1-Norm (BatchNormalizat  (None, 16, 16, 16)       512       \n",
            " ion)                                                            \n",
            "                                                                 \n",
            " Conv1-LeakyReLU (LeakyReLU)  (None, 16, 16, 16)       0         \n",
            "                                                                 \n",
            " Conv1-Pool (MaxPooling2D)   (None, 16, 16, 16)        0         \n",
            "                                                                 \n",
            " Conv2 (Conv2D)              (None, 8, 8, 20)          8020      \n",
            "                                                                 \n",
            " Conv2-Norm (BatchNormalizat  (None, 8, 8, 20)         128       \n",
            " ion)                                                            \n",
            "                                                                 \n",
            " Conv2-LeakyReLU (LeakyReLU)  (None, 8, 8, 20)         0         \n",
            "                                                                 \n",
            " Conv2-Pool (MaxPooling2D)   (None, 8, 8, 20)          0         \n",
            "                                                                 \n",
            " Conv3 (Conv2D)              (None, 8, 8, 20)          3620      \n",
            "                                                                 \n",
            " Conv3-Norm (BatchNormalizat  (None, 8, 8, 20)         128       \n",
            " ion)                                                            \n",
            "                                                                 \n",
            " Conv3-LeakyReLU (LeakyReLU)  (None, 8, 8, 20)         0         \n",
            "                                                                 \n",
            " Flatten (Flatten)           (None, 1280)              0         \n",
            "                                                                 \n",
            " Dense1 (Dense)              (None, 160)               204960    \n",
            "                                                                 \n",
            " Dropout1 (Dropout)          (None, 160)               0         \n",
            "                                                                 \n",
            " Dense2 (Dense)              (None, 20)                3220      \n",
            "                                                                 \n",
            " Dropout2 (Dropout)          (None, 20)                0         \n",
            "                                                                 \n",
            " Dense3 (Dense)              (None, 2)                 42        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 221,846\n",
            "Trainable params: 221,078\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "with open(f\"{model_path}/cnn_model_export.json\", \"r\") as readfile:\n",
        "    cnn_model_export = json.load(readfile)\n",
        "\n",
        "cnn_model = tf.keras.models.model_from_json(cnn_model_export)\n",
        "cnn_model_untrained = tf.keras.models.model_from_json(cnn_model_export)\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "749733fd-472e-4cc2-be64-5f3bc138c757",
      "metadata": {
        "id": "749733fd-472e-4cc2-be64-5f3bc138c757"
      },
      "source": [
        "**Here is how the model was defined in the first place.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea52ff1a-29b7-465e-8dcd-2cbd5213e7a3",
      "metadata": {
        "id": "ea52ff1a-29b7-465e-8dcd-2cbd5213e7a3"
      },
      "outputs": [],
      "source": [
        "# cnn_model = tf.keras.Sequential(\n",
        "#     layers = [\n",
        "#         # First Convolution Layer\n",
        "#         tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=(2, 2), padding=\"same\", name=\"Conv1\"),\n",
        "#         tf.keras.layers.BatchNormalization(axis=[1, 2], momentum=0, center=False, scale=False, name=\"Conv1-Norm\"),\n",
        "#         tf.keras.layers.LeakyReLU(name=\"Conv1-LeakyReLU\"),\n",
        "#         tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"Conv1-Pool\"),\n",
        "#         # Second Convolution Layer\n",
        "#         tf.keras.layers.Conv2D(filters=20, kernel_size=5, strides=(2, 2), padding=\"same\", name=\"Conv2\"),\n",
        "#         tf.keras.layers.BatchNormalization(axis=[1, 2], momentum=0, center=False, scale=False, name=\"Conv2-Norm\"),\n",
        "#         tf.keras.layers.LeakyReLU(name=\"Conv2-LeakyReLU\"),\n",
        "#         tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\", name=\"Conv2-Pool\"),\n",
        "#         # Third Convolution Layer\n",
        "#         tf.keras.layers.Conv2D(filters=20, kernel_size=3, strides=(1, 1), padding=\"same\", name=\"Conv3\"),\n",
        "#         tf.keras.layers.BatchNormalization(axis=[1, 2], momentum=0, center=False, scale=False, name=\"Conv3-Norm\"),\n",
        "#         tf.keras.layers.LeakyReLU(name=\"Conv3-LeakyReLU\"),\n",
        "#         # Three Dense Layers\n",
        "#         tf.keras.layers.Flatten(name=\"Flatten\"),\n",
        "#         tf.keras.layers.Dense(160, activation=\"leaky_relu\", name=\"Dense1\"),\n",
        "#         tf.keras.layers.Dropout(rate=0.3, name=\"Dropout1\"),\n",
        "#         tf.keras.layers.Dense(20, activation=\"leaky_relu\", name=\"Dense2\"),\n",
        "#         tf.keras.layers.Dropout(rate=0.3, name=\"Dropout2\"),\n",
        "#         tf.keras.layers.Dense(2, activation=\"softmax\", name=\"Dense3\"),\n",
        "#     ],\n",
        "#     name = \"cnn_model\"\n",
        "# )\n",
        "\n",
        "# cnn_model.build(tf.TensorShape([None, 32, 32, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "398c719c-b568-4c07-861d-792d939cfa53",
      "metadata": {
        "id": "398c719c-b568-4c07-861d-792d939cfa53"
      },
      "source": [
        "## Weight Load"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9c454e7-e0c6-4878-a8ae-734833366ade",
      "metadata": {
        "id": "d9c454e7-e0c6-4878-a8ae-734833366ade"
      },
      "source": [
        "**Here is how to import pretrained weights. In this way, you don't have to train the weights again.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54677761-3241-4ad7-98c4-711baecd2e93",
      "metadata": {
        "id": "54677761-3241-4ad7-98c4-711baecd2e93",
        "outputId": "c0c22419-4816-4cde-df20-d4b13719e9dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x22f2c8b78b0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn_model.load_weights(f\"{model_path}/cnn_model_weights_TA\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "401be589-b473-493f-a256-3981e3597cb5",
      "metadata": {
        "id": "401be589-b473-493f-a256-3981e3597cb5"
      },
      "source": [
        "**This is how the model was trained in the first place.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39781c0b-652c-43ff-a2cc-e4874fe44f8b",
      "metadata": {
        "id": "39781c0b-652c-43ff-a2cc-e4874fe44f8b"
      },
      "outputs": [],
      "source": [
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "# loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "# metrics = [tf.keras.metrics.CategoricalAccuracy()]\n",
        "\n",
        "# cnn_model.compile(optimizer=optimizer,\n",
        "#                   loss=loss,\n",
        "#                   metrics=metrics)\n",
        "\n",
        "# cnn_model.fit(x = image_train, y = oh_label_train,\n",
        "#               epochs = 30, batch_size = 64,\n",
        "#               validation_data = (image_test, oh_label_test), validation_freq = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82aee7e2-de05-4372-8b1e-d75c31508993",
      "metadata": {
        "id": "82aee7e2-de05-4372-8b1e-d75c31508993"
      },
      "source": [
        "**Finally, this is how to export a model into a JSON file and save the weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f6d858f-ffdd-49a6-8114-de72276980b2",
      "metadata": {
        "id": "4f6d858f-ffdd-49a6-8114-de72276980b2"
      },
      "outputs": [],
      "source": [
        "# cnn_model_export = cnn_model.to_json()\n",
        "# with open(f\"{model_path}/cnn_model_export.json\", \"w\", encoding = \"utf-8\") as outfile:\n",
        "#     json.dump(cnn_model_export, outfile)\n",
        "\n",
        "# # you can change the name of the exported weights\n",
        "# cnn_model.save_weights(f\"{model_path}/cnn_model_weights_TA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce144e8c-3c85-4132-8564-24e6c7b276a9",
      "metadata": {
        "id": "ce144e8c-3c85-4132-8564-24e6c7b276a9",
        "outputId": "1ad718a4-eed1-4022-f837-6d7bc959de55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  trained model's accuracy = 0.7670\n",
            "untrained model's accuracy = 0.5000\n"
          ]
        }
      ],
      "source": [
        "cifar_class_array = np.array(cifar_class_list)\n",
        "predicted_labels = cifar_class_array[tf.argmax(cnn_model(image_test), axis=1)]\n",
        "predicted_labels_untrained = cifar_class_array[tf.argmax(cnn_model_untrained(image_test), axis=1)]\n",
        "\n",
        "model_accuracy = np.sum(label_test == predicted_labels)/len(label_test)\n",
        "model_accuracy_untrained = np.sum(label_test == predicted_labels_untrained)/len(label_test)\n",
        "print(f\"  trained model's accuracy = {model_accuracy:0.4f}\")\n",
        "print(f\"untrained model's accuracy = {model_accuracy_untrained:0.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "202945fa-5ecc-452a-a430-2df29eb791a1",
      "metadata": {
        "id": "202945fa-5ecc-452a-a430-2df29eb791a1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "436e1549-8a33-4421-bdf0-22afd8b229e9",
      "metadata": {
        "id": "436e1549-8a33-4421-bdf0-22afd8b229e9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2002b78a-a106-4a15-8369-aae6b646baf3",
      "metadata": {
        "id": "2002b78a-a106-4a15-8369-aae6b646baf3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}